# ‚öñÔ∏è Crawler TJPA: Extrator de Dados Processuais

Este projeto √© um prot√≥tipo desenvolvido para a
extra√ß√£o, normaliza√ß√£o e persist√™ncia de dados jur√≠dicos do Tribunal de
Justi√ßa do Par√° [(TJPA)](https://consulta-processual-unificada-prd.tjpa.jus.br/#/consulta). O foco principal √© a supera√ß√£o de barreiras de
valida√ß√£o e a efici√™ncia no consumo de APIs REST internas.

------------------------------------------------------------------------

## üìù Descri√ß√£o da Fonte e Desafios T√©cnicos

A fonte de dados √© o portal de consulta p√∫blica do TJPA, que
disponibiliza informa√ß√µes atrav√©s de endpoints JSON estruturados (Capa e
Movimenta√ß√£o).

### Principais Desafios

-   **Valida√ß√£o Matem√°tica:** O servidor exige o c√°lculo exato do D√≠gito
    Verificador (ISO 7064 Mod 97-10). Requisi√ß√µes com DVs inv√°lidos s√£o
    descartadas antes da consulta ao banco.

-   **Fragmenta√ß√£o de Endpoints:** Os dados n√£o residem em um √∫nico
    local. √â necess√°rio capturar IDs internos (`cdDocProcesso`) na Capa
    para acessar as Movimenta√ß√µes.

-   **Seguran√ßa (WAF):** Monitoramento ativo de Rate Limiting. O
    firewall do tribunal frequentemente retorna p√°ginas HTML de erro
    quando detecta comportamento automatizado agressivo.

-   **Gaps de Numera√ß√£o:** A distribui√ß√£o de processos no PJe n√£o √©
    linear, apresentando grandes "buracos" sequenciais que podem travar
    crawlers simplistas.

------------------------------------------------------------------------

## üöÄ Estrat√©gias de Coleta Adotadas

Para garantir efici√™ncia e furtividade, foram implementadas as seguintes
t√°ticas:

-   **Engenharia Reversa do CNJ:** Desconstru√ß√£o da m√°scara do processo
    para gera√ß√£o din√¢mica de n√∫meros v√°lidos via algoritmo de M√≥dulo 97.

-   **Requisi√ß√µes At√¥micas (Requests):** Substitui√ß√£o de emuladores de
    browser (Selenium) por chamadas HTTP diretas, reduzindo o consumo de
    mem√≥ria em at√© 90%.

-   **Sondagem de Densidade (Scouting):** Uso de t√©cnica de probing para
    localizar as faixas num√©ricas onde os processos est√£o realmente
    concentrados antes de iniciar a varredura em massa.

-   **Intervalos Aleat√≥rios (Jitter):** Implementa√ß√£o de
    `random.uniform()` entre requisi√ß√µes para simular o tempo de leitura
    humano e evitar bloqueios por IP.

------------------------------------------------------------------------

## üìä Resultados Obtidos com o Prot√≥tipo

-   **Velocidade:** Capacidade de processar aproximadamente 60--100
    processos por minuto (variando conforme a lat√™ncia do servidor).

-   **Estabilidade:** Recupera√ß√£o autom√°tica de erros de rede sem
    interrup√ß√£o do script.

-   **Armazenamento:** Gera√ß√£o de arquivos JSONL, permitindo que cada
    registro seja lido ou escrito de forma independente, ideal para
    pipelines de Big Data.

------------------------------------------------------------------------

## ‚úÖ Valida√ß√µes de Qualidade de Dados

Para garantir que a sa√≠da seja "Jusbrasil Style" (pronta para consumo),
o crawler executa:

-   **Normaliza√ß√£o de Tipos:** Convers√£o de strings de data e listas de
    advogados em objetos estruturados.

-   **Checkpoint System:** Grava√ß√£o do estado da coleta em tempo real.
    Se o processo for interrompido, ele retoma exatamente do √∫ltimo CNJ
    v√°lido.

-   **Sanitiza√ß√£o de Resposta:** Verifica√ß√£o de `Content-Type`. O script
    ignora retornos que n√£o sejam JSON v√°lido (como erros 404 ou 503
    mascarados em HTML).

------------------------------------------------------------------------

## üõ†Ô∏è Poss√≠veis Melhorias e Manuten√ß√£o

Para escalar o projeto e reduzir falhas recorrentes, sugere-se:

-   **Rota√ß√£o de Proxies:** Implementar um pool de IPs para contornar
    bloqueios geogr√°ficos ou de volume do WAF.

-   **Cont√™ineriza√ß√£o (Docker):** Isolar o ambiente para garantir que o
    crawler rode de forma id√™ntica em qualquer servidor ou inst√¢ncia na
    nuvem.

-   **Integra√ß√£o com Banco de Dados:** Migrar de JSONL para um banco
    NoSQL (como MongoDB) para facilitar buscas complexas e evitar
    duplicidade de registros.

-   **Monitoramento de Vers√£o:** Criar um alerta para mudan√ßas nos
    campos da API do tribunal, garantindo que o parser seja atualizado
    proativamente.
